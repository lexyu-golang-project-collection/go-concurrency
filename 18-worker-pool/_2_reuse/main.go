package main

import (
	"context"
	"fmt"
	"math"
	"math/rand"
	"sync"
	"sync/atomic"
	"time"
)

// =============================================================
// Core Types and Interfaces
// =============================================================

type Job interface{}
type Result interface{}

// åŒ…è£åŸ·è¡Œçµæœå’ŒéŒ¯èª¤
type JobResult[R Result] struct {
	Result R
	Error  error
}

// å‡½æ•¸ç¾åœ¨å¯ä»¥è¿”å›éŒ¯èª¤
type Worker[T Job, R Result] func(ctx context.Context, workerID int, job T) (R, error)

// =============================================================
// Retry Policy Configuration
// =============================================================

// å®šç¾©é‡è©¦ç­–ç•¥
type RetryPolicy struct {
	MaxRetries      int           // æœ€å¤§é‡è©¦æ¬¡æ•¸
	BaseDelay       time.Duration // åŸºç¤å»¶é²æ™‚é–“
	MaxDelay        time.Duration // æœ€å¤§å»¶é²æ™‚é–“
	BackoffStrategy BackoffStrategy
	JitterType      JitterType
}

type BackoffStrategy int

const (
	FixedBackoff BackoffStrategy = iota
	LinearBackoff
	ExponentialBackoff
)

type JitterType int

const (
	NoJitter JitterType = iota
	FullJitter
	EqualJitter
	DecorrelatedJitter
)

// =============================================================
// Worker Pool Structure and Internal Types
// =============================================================

type WorkerPool[T, R any] struct {
	// Configuration
	numOfWorkers int
	worker       Worker[T, R]
	retryPolicy  RetryPolicy

	// Channels
	jobs      chan T
	results   chan JobResult[R]
	retryJobs chan jobWithAttempt[T]

	// Concurrency Control
	wg          sync.WaitGroup
	ctx         context.Context
	cancel      context.CancelFunc
	jobsOpen    atomic.Bool
	pendingJobs atomic.Int64 // è¿½è¹¤é€²è¡Œä¸­çš„å·¥ä½œ
}

type jobWithAttempt[T Job] struct {
	job     T
	attempt int
}

// =============================================================
// Constructor and Initialization
// =============================================================

func NewWorkerPool[T Job, R Result](
	numOfWorkers, bufferSize int,
	worker Worker[T, R],
	retryPolicy RetryPolicy,
) *WorkerPool[T, R] {
	ctx, cancel := context.WithCancel(context.Background())

	pool := &WorkerPool[T, R]{
		// Configuration
		numOfWorkers: numOfWorkers,
		worker:       worker,
		retryPolicy:  retryPolicy,

		// Channels
		jobs:      make(chan T, bufferSize),
		results:   make(chan JobResult[R], bufferSize),
		retryJobs: make(chan jobWithAttempt[T], bufferSize),

		// Concurrency Control
		ctx:    ctx,
		cancel: cancel,
	}

	pool.jobsOpen.Store(true)
	return pool
}

// =============================================================
// Pool Lifecycle Management
// =============================================================

func (pool *WorkerPool[T, R]) Start() {
	// å•Ÿå‹• workers
	for i := 1; i <= pool.numOfWorkers; i++ {
		pool.wg.Add(1)
		go pool.workerRoutine(i)
	}

	// ç›£æ§æ‰€æœ‰å·¥ä½œå®Œæˆ
	go pool.monitorCompletion()
}

func (pool *WorkerPool[T, R]) monitorCompletion() {
	// ç­‰å¾…æ‰€æœ‰ workers å®Œæˆ
	pool.wg.Wait()
	close(pool.results)
}

func (pool *WorkerPool[T, R]) Stop() {
	pool.cancel()
}

func (pool *WorkerPool[T, R]) CloseQueue() {
	if pool.jobsOpen.CompareAndSwap(true, false) {
		close(pool.jobs)

		// å•Ÿå‹•è¶…æ™‚æ©Ÿåˆ¶ï¼Œç¢ºä¿ workers æœ€çµ‚æœƒé€€å‡º
		go func() {
			// ç­‰å¾…ä¸€æ®µæ™‚é–“è®“ retry å®Œæˆ
			timeout := time.Duration(pool.retryPolicy.MaxRetries) * pool.retryPolicy.MaxDelay * 2
			if timeout > 30*time.Second {
				timeout = 30 * time.Second
			}

			time.Sleep(timeout)

			// å¦‚æœé‚„æœ‰å¾…è™•ç†çš„å·¥ä½œï¼Œå¼·åˆ¶åœæ­¢
			if pool.pendingJobs.Load() > 0 {
				pool.cancel()
			}
		}()
	}
}

// =============================================================
// Worker Execution Logic
// =============================================================

func (pool *WorkerPool[T, R]) workerRoutine(workerID int) {
	defer pool.wg.Done()

	for {
		select {
		case <-pool.ctx.Done():
			return
		case job, ok := <-pool.jobs:
			if !ok {
				// jobs channel å·²é—œé–‰ï¼Œä½†ç¹¼çºŒè™•ç† retry jobs
				pool.processRetryJobs(workerID)
				return
			}
			pool.processJob(workerID, job, 0)
		case jobAttempt, ok := <-pool.retryJobs:
			if !ok {
				return
			}
			pool.processJob(workerID, jobAttempt.job, jobAttempt.attempt)
		}
	}
}

func (pool *WorkerPool[T, R]) processRetryJobs(workerID int) {
	for {
		select {
		case <-pool.ctx.Done():
			return
		case jobAttempt, ok := <-pool.retryJobs:
			if !ok {
				return
			}
			pool.processJob(workerID, jobAttempt.job, jobAttempt.attempt)
		default:
			// æ²’æœ‰æ›´å¤š retry jobsï¼Œæª¢æŸ¥æ˜¯å¦é‚„æœ‰å…¶ä»–å·¥ä½œ
			if pool.pendingJobs.Load() == 0 {
				return
			}
			time.Sleep(10 * time.Millisecond) // çŸ­æš«ç­‰å¾…
		}
	}
}

func (pool *WorkerPool[T, R]) processJob(workerID int, job T, attempt int) {
	pool.pendingJobs.Add(1)
	defer pool.pendingJobs.Add(-1)

	result, err := pool.worker(pool.ctx, workerID, job)

	if err != nil && attempt < pool.retryPolicy.MaxRetries {
		// éœ€è¦é‡è©¦
		delay := pool.calculateDelay(attempt)

		// éé˜»å¡å»¶é²
		select {
		case <-time.After(delay):
		case <-pool.ctx.Done():
			return
		}

		select {
		case pool.retryJobs <- jobWithAttempt[T]{job: job, attempt: attempt + 1}:
		case <-pool.ctx.Done():
			return
		}
		return
	}

	// ç™¼é€çµæœï¼ˆæˆåŠŸæˆ–æœ€çµ‚å¤±æ•—ï¼‰
	select {
	case pool.results <- JobResult[R]{Result: result, Error: err}:
	case <-pool.ctx.Done():
		return
	}
}

// =============================================================
// Retry and Backoff Algorithm Implementation
// =============================================================

func (pool *WorkerPool[T, R]) calculateDelay(attempt int) time.Duration {
	var delay time.Duration

	switch pool.retryPolicy.BackoffStrategy {
	case FixedBackoff:
		delay = pool.retryPolicy.BaseDelay
	case LinearBackoff:
		delay = time.Duration(attempt+1) * pool.retryPolicy.BaseDelay
	case ExponentialBackoff:
		delay = time.Duration(math.Pow(2, float64(attempt))) * pool.retryPolicy.BaseDelay
	}

	// æ‡‰ç”¨æœ€å¤§å»¶é²é™åˆ¶
	if delay > pool.retryPolicy.MaxDelay {
		delay = pool.retryPolicy.MaxDelay
	}

	// æ‡‰ç”¨ Jitter
	return pool.applyJitter(delay, attempt)
}

func (pool *WorkerPool[T, R]) applyJitter(delay time.Duration, attempt int) time.Duration {
	switch pool.retryPolicy.JitterType {
	case NoJitter:
		return delay
	case FullJitter:
		// éš¨æ©Ÿ 0 åˆ° delay ä¹‹é–“
		return time.Duration(rand.Int63n(int64(delay)))
	case EqualJitter:
		// ä¸€åŠå›ºå®šå»¶é² + ä¸€åŠéš¨æ©Ÿå»¶é²
		half := delay / 2
		return half + time.Duration(rand.Int63n(int64(half)))
	case DecorrelatedJitter:
		// AWS å»ºè­°çš„ decorrelated jitter
		min := int64(pool.retryPolicy.BaseDelay)
		max := int64(delay * 3)
		if max <= min {
			return pool.retryPolicy.BaseDelay
		}
		return time.Duration(min + rand.Int63n(max-min))
	default:
		return delay
	}
}

// =============================================================
// Public API Methods
// =============================================================

func (pool *WorkerPool[T, R]) Submit(job T) {
	if !pool.jobsOpen.Load() {
		return // ä¸æ¥å—æ–°å·¥ä½œ
	}

	select {
	case pool.jobs <- job:
	case <-pool.ctx.Done():
	}
}

func (pool *WorkerPool[T, R]) Results() <-chan JobResult[R] {
	return pool.results
}

// =============================================================
// Example Usage and Demo Types
// =============================================================

type DataJob struct {
	ID    int
	Value string
}

type DataResult struct {
	JobID     int
	Processed string
	WorkerID  int
}

func main() {
	// å»ºç«‹é‡è©¦ç­–ç•¥
	retryPolicy := RetryPolicy{
		MaxRetries:      3,
		BaseDelay:       100 * time.Millisecond,
		MaxDelay:        5 * time.Second,
		BackoffStrategy: ExponentialBackoff,
		JitterType:      EqualJitter,
	}

	// å»ºç«‹æœƒå¶çˆ¾å¤±æ•—çš„å·¥ä½œè™•ç†å‡½æ•¸
	worker := func(ctx context.Context, workerID int, job DataJob) (DataResult, error) {
		// æ¨¡æ“¬ 20% çš„å¤±æ•—ç‡
		if rand.Float32() < 0.2 {
			return DataResult{}, fmt.Errorf("simulated failure for job %d", job.ID)
		}

		// æ¨¡æ“¬è™•ç†æ™‚é–“
		time.Sleep(50 * time.Millisecond)

		return DataResult{
			JobID:     job.ID,
			Processed: fmt.Sprintf("Processed-%s", job.Value),
			WorkerID:  workerID,
		}, nil
	}

	// å»ºç«‹å·¥ä½œæ± 
	pool := NewWorkerPool[DataJob, DataResult](5, 100, worker, retryPolicy)
	pool.Start()

	// æäº¤å·¥ä½œ
	go func() {
		for i := 0; i < 50; i++ {
			pool.Submit(DataJob{
				ID:    i,
				Value: fmt.Sprintf("Data-%d", i),
			})
		}
		pool.CloseQueue()
	}()

	// è™•ç†çµæœ
	successCount := 0
	failureCount := 0

	for result := range pool.Results() {
		if result.Error != nil {
			fmt.Printf("âŒ Final failure: JobID=%d, Error=%s\n",
				result.Result.JobID, result.Error)
			failureCount++
		} else {
			fmt.Printf("âœ… Success: JobID=%d, Processed=%s, WorkerID=%d\n",
				result.Result.JobID, result.Result.Processed, result.Result.WorkerID)
			successCount++
		}
	}

	fmt.Printf("\nğŸ“Š Results: %d successful, %d failed\n", successCount, failureCount)
}
